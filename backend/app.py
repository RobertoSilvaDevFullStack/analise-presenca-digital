from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import os
from datetime import datetime
from supabase import create_client, Client
from scraper_modules.website_scraper import WebsiteScraper
from scraper_modules.google_scraper import GoogleScraper
import json
import traceback

# Carregar vari√°veis de ambiente
load_dotenv()

app = Flask(__name__)

# Configurar CORS mais permissivo
CORS(app, resources={
    r"/*": {
        "origins": ["http://localhost", "http://localhost:80", "http://127.0.0.1", "http://0.0.0.0"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization", "Accept"]
    }
})

# Configurar Supabase - com verifica√ß√£o
supabase_url = os.getenv('SUPABASE_URL')
supabase_key = os.getenv('SUPABASE_KEY')

if supabase_url and supabase_key:
    try:
        supabase: Client = create_client(supabase_url, supabase_key)
        print("‚úÖ Supabase configurado com sucesso")
    except Exception as e:
        print(f"‚ùå Erro ao configurar Supabase: {e}")
        supabase = None
else:
    print("‚ö†Ô∏è  Supabase n√£o configurado - vari√°veis de ambiente n√£o encontradas")
    supabase = None

class AnalysisEngine:
    @staticmethod
    def analyze_website_data(website_data):
        """Analisa dados do website e gera relat√≥rio profissional"""
        url = website_data.get('url', 'Site analisado')
        
        # An√°lise da estrutura e desenvolvedor
        estrutura_info = []
        cms_info = website_data.get('cms_detected', 'N√£o identificado')
        developer_info = website_data.get('developer_info', 'N√£o identificado')
        
        if cms_info != 'N√£o identificado':
            estrutura_info.append(f"O site utiliza {cms_info} como plataforma.")
        else:
            estrutura_info.append("N√£o foi poss√≠vel identificar publicamente a plataforma (CMS) utilizada.")
        
        if developer_info != 'N√£o identificado':
            estrutura_info.append(f"Desenvolvido por: {developer_info}.")
        else:
            estrutura_info.append("N√£o foi poss√≠vel identificar publicamente a empresa desenvolvedora do site.")
        
        # An√°lise t√©cnica
        load_time = website_data.get('load_time', 0)
        has_ssl = website_data.get('has_ssl', False)
        status_code = website_data.get('status_code', 0)
        
        if status_code == 200:
            estrutura_info.append("O site est√° funcionalmente ativo e bem organizado.")
        
        if has_ssl:
            estrutura_info.append("Possui certificado SSL (HTTPS) implementado.")
        else:
            estrutura_info.append("‚ö†Ô∏è Site sem certificado SSL - vulnerabilidade de seguran√ßa.")
        
        estrutura_desc = " ".join(estrutura_info)
        
        # Melhorias identificadas
        melhorias = []
        
        # SEO e Performance
        if load_time > 3:
            melhorias.append("**Otimiza√ß√£o de Performance**: O tempo de carregamento est√° acima do recomendado (>3s). Recomenda-se otimiza√ß√£o de imagens, implementa√ß√£o de cache e minifica√ß√£o de recursos para melhorar a experi√™ncia do usu√°rio e o ranking no Google.")
        else:
            melhorias.append("**Otimiza√ß√£o para SEO**: Implementar estrat√©gias de SEO t√©cnico e de conte√∫do. Criar um calend√°rio editorial focado em palavras-chave relevantes para o neg√≥cio, otimizar meta descri√ß√µes e titles, e desenvolver conte√∫do que responda √†s d√∫vidas do p√∫blico-alvo.")
        
        # CRO (Conversion Rate Optimization)
        melhorias.append("**Otimiza√ß√£o de Convers√£o (CRO)**: An√°lise detalhada do funil de convers√£o para identificar pontos de atrito. Implementa√ß√£o de CTAs mais proeminentes, otimiza√ß√£o de formul√°rios e cria√ß√£o de landing pages espec√≠ficas para diferentes campanhas.")
        
        # Conte√∫do e UX
        melhorias.append("**Experi√™ncia do Usu√°rio (UX)**: Melhoria na navegabilidade e cria√ß√£o de conte√∫do visual mais envolvente. Implementa√ß√£o de chatbots, depoimentos de clientes e elementos de prova social para aumentar a confian√ßa e convers√£o.")
        
        # Marketing Digital
        necessidades = []
        necessidades.append("**Google Ads e Hotel Ads**: N√£o foram identificados an√∫ncios pagos com o nome da empresa. Isso permite que OTA's (Online Travel Agencies) capturem reservas de usu√°rios que j√° procuram especificamente pelo neg√≥cio.")
        necessidades.append("**Presen√ßa Digital**: An√°lise completa da presen√ßa digital revela oportunidades de melhoria na estrat√©gia de marketing digital integrada.")
        
        return {
            'estrutura_desenvolvedor': estrutura_desc,
            'melhorias_identificadas': melhorias,
            'necessidades_identificadas': necessidades
        }
    
    @staticmethod
    def analyze_google_data(google_data):
        """Analisa dados do Google e gera relat√≥rio profissional"""
        url = google_data.get('url', 'Site analisado')
        google_analysis = google_data.get('google_analysis', {})
        recommendations = google_data.get('recommendations', {})
        
        # An√°lise de SEO
        seo_status = google_analysis.get('seo_status', {})
        seo_info = []
        if isinstance(seo_status, dict):
            status = seo_status.get('status', 'N√£o avaliado')
            seo_info.append(f"Status SEO: {status}")
            
            priority_actions = seo_status.get('priority_actions', [])
            if priority_actions:
                seo_info.append("A√ß√µes priorit√°rias: " + ", ".join(priority_actions))
        
        # An√°lise de presen√ßa social
        social_presence = google_analysis.get('social_presence', {})
        social_info = []
        if isinstance(social_presence, dict):
            platforms = social_presence.get('platforms_found', [])
            if platforms:
                social_info.append(f"Plataformas encontradas: {', '.join(platforms)}")
            else:
                social_info.append("**‚ö†Ô∏è Presen√ßa limitada nas redes sociais detectada**")
            
            social_recommendations = social_presence.get('recommendations', [])
            if social_recommendations:
                social_info.extend(social_recommendations)
        
        # An√°lise de an√∫ncios
        ads_presence = google_analysis.get('ads_presence', {})
        ads_info = []
        if isinstance(ads_presence, dict):
            ads_status = ads_presence.get('status', 'N√£o avaliado')
            ads_info.append(f"Presen√ßa publicit√°ria: {ads_status}")
            
            opportunities = ads_presence.get('opportunities', [])
            if opportunities:
                ads_info.append("Oportunidades identificadas:")
                ads_info.extend([f"‚Ä¢ {opp}" for opp in opportunities])
        
        # An√°lise de reputa√ß√£o
        reputation = google_analysis.get('online_reputation', {})
        reputation_info = []
        if isinstance(reputation, dict):
            rep_status = reputation.get('status', 'N√£o avaliado')
            reputation_info.append(f"Reputa√ß√£o online: {rep_status}")
            
            reviews_count = reputation.get('reviews_count', 0)
            if reviews_count > 0:
                sentiment = reputation.get('sentiment', 'Neutro')
                reputation_info.append(f"Avalia√ß√µes encontradas: {reviews_count} (Sentimento: {sentiment})")
        
        # An√°lise de mercado
        market_position = google_analysis.get('market_position', {})
        market_info = []
        if isinstance(market_position, dict):
            competitors = market_position.get('competitors_identified', 0)
            if competitors > 0:
                market_info.append(f"Concorrentes identificados: {competitors}")
            
            market_status = market_position.get('market_status', '')
            if market_status:
                market_info.append(f"Status do mercado: {market_status}")
        
        # Estrat√©gias recomendadas baseadas no Google
        estrategias_google = []
        
        # SEO
        seo_improvements = recommendations.get('seo_improvements', [])
        if seo_improvements:
            estrategias_google.append("**SEO e Visibilidade Online**:")
            estrategias_google.extend([f"‚Ä¢ {imp}" for imp in seo_improvements[:3]])
        
        # Marketing Digital
        digital_marketing = recommendations.get('digital_marketing', [])
        if digital_marketing:
            estrategias_google.append("**Marketing Digital**:")
            estrategias_google.extend([f"‚Ä¢ {dm}" for dm in digital_marketing[:3]])
        
        # Melhorias no site
        website_improvements = recommendations.get('website_improvements', [])
        if website_improvements:
            estrategias_google.append("**Melhorias no Website**:")
            estrategias_google.extend([f"‚Ä¢ {wi}" for wi in website_improvements[:3]])
        
        return {
            'seo_analise': " ".join(seo_info) if seo_info else "An√°lise SEO n√£o dispon√≠vel",
            'presenca_social': " ".join(social_info) if social_info else "An√°lise de redes sociais n√£o dispon√≠vel",
            'presenca_publicitaria': " ".join(ads_info) if ads_info else "An√°lise publicit√°ria n√£o dispon√≠vel",
            'reputacao_online': " ".join(reputation_info) if reputation_info else "An√°lise de reputa√ß√£o n√£o dispon√≠vel",
            'posicao_mercado': " ".join(market_info) if market_info else "An√°lise de mercado n√£o dispon√≠vel",
            'estrategias_google': estrategias_google
        }
    
    @staticmethod
    def _format_number(num):
        """Formata n√∫meros para exibi√ß√£o"""
        if num is None:
            return "N/A"
        if num >= 1000000:
            return f"{num/1000000:.1f}M"
        elif num >= 1000:
            return f"{num/1000:.1f}K"
        else:
            return str(num)

@app.route('/analisar', methods=['POST', 'OPTIONS'])
def analisar():
    # Handle preflight CORS request
    if request.method == 'OPTIONS':
        return jsonify({}), 200
        
    try:
        if not request.is_json:
            return jsonify({'error': 'Content-Type deve ser application/json'}), 400
            
        data = request.json
        if not data:
            return jsonify({'error': 'Dados JSON inv√°lidos'}), 400
            
        website_url = data.get('website_url', '').strip()
        
        print(f"üìù Recebida requisi√ß√£o - Site: {website_url}")
        
        if not website_url:
            return jsonify({'error': 'URL do website deve ser fornecido'}), 400
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'website_analysis': None,
            'google_analysis': None
        }
        
        # An√°lise do Website
        if website_url:
            print(f"üîç Iniciando an√°lise do website: {website_url}")
            try:
                website_scraper = WebsiteScraper()
                website_data = website_scraper.scrape(website_url)
                website_analysis = AnalysisEngine.analyze_website_data(website_data)
                
                result['website_analysis'] = {
                    'url': website_url,
                    'raw_data': website_data,
                    'relatorio': {
                        'titulo': f"An√°lise do Site: {website_url}",
                        'estrutura_desenvolvedor': website_analysis['estrutura_desenvolvedor'],
                        'melhorias_identificadas': website_analysis['melhorias_identificadas'],
                        'necessidades_identificadas': website_analysis['necessidades_identificadas']
                    }
                }
                print("‚úÖ An√°lise do website conclu√≠da")
            except Exception as e:
                print(f"‚ùå Erro na an√°lise do website: {e}")
                result['website_analysis'] = {
                    'url': website_url,
                    'raw_data': {'error': f'Erro ao analisar website: {str(e)}'},
                    'relatorio': {
                        'titulo': f"An√°lise do Site: {website_url}",
                        'estrutura_desenvolvedor': 'N√£o foi poss√≠vel analisar a estrutura do site devido a problemas t√©cnicos.',
                        'melhorias_identificadas': ['Recomenda-se uma an√°lise t√©cnica manual para identificar oportunidades de melhoria.'],
                        'necessidades_identificadas': ['Verifica√ß√£o t√©cnica necess√°ria para diagn√≥stico completo.']
                    }
                }
        
        # An√°lise do Google
        print(f"üîç Iniciando an√°lise do Google para: {website_url}")
        try:
            google_scraper = GoogleScraper()
            google_data = google_scraper.search_website_info(website_url)
            google_analysis = AnalysisEngine.analyze_google_data(google_data)
            
            result['google_analysis'] = {
                'url': website_url,
                'raw_data': google_data,
                'relatorio': {
                    'titulo': f"An√°lise do Google: {website_url}",
                    'seo_analise': google_analysis['seo_analise'],
                    'presenca_social': google_analysis['presenca_social'],
                    'presenca_publicitaria': google_analysis['presenca_publicitaria'],
                    'reputacao_online': google_analysis['reputacao_online'],
                    'posicao_mercado': google_analysis['posicao_mercado'],
                    'estrategias_google': google_analysis['estrategias_google']
                }
            }
            print("‚úÖ An√°lise do Google conclu√≠da")
        except Exception as e:
            print(f"‚ùå Erro na an√°lise do Google: {e}")
            result['google_analysis'] = {
                'url': website_url,
                'raw_data': {'error': f'Erro ao analisar no Google: {str(e)}'},
                'relatorio': {
                    'titulo': f"An√°lise do Google: {website_url}",
                    'seo_analise': 'N√£o foi poss√≠vel realizar an√°lise SEO via Google.',
                    'presenca_social': 'An√°lise de presen√ßa social n√£o dispon√≠vel.',
                    'presenca_publicitaria': 'An√°lise publicit√°ria n√£o dispon√≠vel.',
                    'reputacao_online': 'An√°lise de reputa√ß√£o n√£o dispon√≠vel.',
                    'posicao_mercado': 'An√°lise de mercado n√£o dispon√≠vel.',
                    'estrategias_google': ['Recomenda-se an√°lise manual para estrat√©gias personalizadas.']
                }
            }
        
        # Salvar no Supabase (se configurado)
        if supabase:
            try:
                supabase.table('analyses').insert({
                    'website_url': website_url or None,
                    'instagram_url': instagram_url or None,
                    'analysis_data': result,
                    'created_at': datetime.now().isoformat()
                }).execute()
                print("‚úÖ Dados salvos no Supabase")
            except Exception as db_error:
                print(f"‚ö†Ô∏è  Erro ao salvar no banco (continuando): {db_error}")
        else:
            print("‚ö†Ô∏è  Supabase n√£o configurado - dados n√£o salvos")
        
        return jsonify(result)
    
    except Exception as e:
        error_msg = f'Erro interno do servidor: {str(e)}'
        print(f"‚ùå {error_msg}")
        print(f"üîç Traceback: {traceback.format_exc()}")
        return jsonify({'error': error_msg}), 500

@app.route('/relatorio-crm', methods=['POST', 'OPTIONS'])
def relatorio_crm():
    """Gera relat√≥rio formatado para CRM RD Station"""
    # Handle preflight CORS request
    if request.method == 'OPTIONS':
        return jsonify({}), 200
        
    try:
        if not request.is_json:
            return jsonify({'error': 'Content-Type deve ser application/json'}), 400
            
        data = request.json
        if not data:
            return jsonify({'error': 'Dados JSON inv√°lidos'}), 400
            
        website_url = data.get('website_url', '').strip()
        instagram_url = data.get('instagram_url', '').strip()
        
        if not website_url and not instagram_url:
            return jsonify({'error': 'Pelo menos um URL deve ser fornecido'}), 400
        
        print(f"üìã Gerando relat√≥rio CRM - Site: {website_url}, Instagram: {instagram_url}")
        
        # Executar an√°lise diretamente
        result = {
            'timestamp': datetime.now().isoformat(),
            'website_analysis': None,
            'instagram_analysis': None
        }
        
        # An√°lise do Website
        if website_url:
            print(f"üîç Iniciando an√°lise do website: {website_url}")
            try:
                website_scraper = WebsiteScraper()
                website_data = website_scraper.scrape(website_url)
                website_analysis = AnalysisEngine.analyze_website_data(website_data)
                
                result['website_analysis'] = {
                    'url': website_url,
                    'raw_data': website_data,
                    'relatorio': {
                        'titulo': f"An√°lise do Site: {website_url}",
                        'estrutura_desenvolvedor': website_analysis['estrutura_desenvolvedor'],
                        'melhorias_identificadas': website_analysis['melhorias_identificadas'],
                        'necessidades_identificadas': website_analysis['necessidades_identificadas']
                    }
                }
                print("‚úÖ An√°lise do website conclu√≠da")
            except Exception as e:
                print(f"‚ùå Erro na an√°lise do website: {e}")
                result['website_analysis'] = {
                    'url': website_url,
                    'raw_data': {'error': f'Erro ao analisar website: {str(e)}'},
                    'relatorio': {
                        'titulo': f"An√°lise do Site: {website_url}",
                        'estrutura_desenvolvedor': 'N√£o foi poss√≠vel analisar a estrutura do site devido a problemas t√©cnicos.',
                        'melhorias_identificadas': ['Recomenda-se uma an√°lise t√©cnica manual para identificar oportunidades de melhoria.'],
                        'necessidades_identificadas': ['Verifica√ß√£o t√©cnica necess√°ria para diagn√≥stico completo.']
                    }
                }
        
        # An√°lise do Instagram
        if instagram_url:
            print(f"üì± Iniciando an√°lise do Instagram: {instagram_url}")
            instagram_scraper = None
            try:
                instagram_scraper = InstagramScraper()
                if not instagram_scraper.driver:
                    raise Exception("Driver do Selenium n√£o dispon√≠vel")
                
                instagram_data = instagram_scraper.scrape(instagram_url)
                instagram_analysis = AnalysisEngine.analyze_instagram_data(instagram_data)
                
                result['instagram_analysis'] = {
                    'url': instagram_url,
                    'raw_data': instagram_data,
                    'relatorio': {
                        'titulo': f"An√°lise do Instagram: @{instagram_data.get('username', instagram_url)}",
                        'perfil_analise': instagram_analysis['perfil_analise'],
                        'atividade_status': instagram_analysis['atividade_status'],
                        'tipo_conta': instagram_analysis['tipo_conta'],
                        'bio_status': instagram_analysis['bio_status'],
                        'estrategias_recomendadas': instagram_analysis['estrategias_recomendadas']
                    }
                }
                print("‚úÖ An√°lise do Instagram conclu√≠da")
            except Exception as e:
                print(f"‚ùå Erro na an√°lise do Instagram: {e}")
                result['instagram_analysis'] = {
                    'url': instagram_url,
                    'raw_data': {'error': f'Erro ao analisar Instagram: {str(e)}'},
                    'relatorio': {
                        'titulo': f"An√°lise do Instagram: {instagram_url}",
                        'perfil_analise': 'N√£o foi poss√≠vel analisar o perfil devido a limita√ß√µes t√©cnicas.',
                        'atividade_status': 'Status de atividade n√£o dispon√≠vel.',
                        'tipo_conta': 'N√£o identificado',
                        'bio_status': 'N√£o foi poss√≠vel verificar',
                        'estrategias_recomendadas': ['Recomenda-se an√°lise manual do perfil para estrat√©gias personalizadas.']
                    }
                }
            finally:
                # Garantir que o driver seja fechado
                if instagram_scraper:
                    instagram_scraper.close_driver()
        
        # Gerar relat√≥rio formatado
        relatorio_texto = gerar_relatorio_texto(result, website_url, instagram_url)
        
        return jsonify({
            'relatorio_crm': relatorio_texto,
            'dados_completos': result,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        error_msg = f'Erro interno do servidor: {str(e)}'
        print(f"‚ùå {error_msg}")
        print(f"üîç Traceback: {traceback.format_exc()}")
        return jsonify({'error': error_msg}), 500

def gerar_relatorio_texto(analysis_data, website_url, instagram_url):
    """Gera relat√≥rio em texto formatado para CRM"""
    relatorio = []
    
    # An√°lise do Website
    if website_url and analysis_data.get('website_analysis'):
        website_rel = analysis_data['website_analysis'].get('relatorio', {})
        
        relatorio.append(f"An√°lise do Site: {website_url}")
        relatorio.append("")
        
        # Estrutura e Desenvolvedor
        estrutura = website_rel.get('estrutura_desenvolvedor', 'N√£o foi poss√≠vel analisar a estrutura.')
        relatorio.append(f"Estrutura e Desenvolvedor: {estrutura}")
        relatorio.append("")
        
        # Melhorias
        melhorias = website_rel.get('melhorias_identificadas', [])
        if melhorias:
            relatorio.append("Melhorias a serem realizadas:")
            relatorio.append("")
            for i, melhoria in enumerate(melhorias, 1):
                relatorio.append(f"{melhoria}")
                relatorio.append("")
        
        # Necessidades
        necessidades = website_rel.get('necessidades_identificadas', [])
        if necessidades:
            relatorio.append("Algumas necessidades j√° identificadas:")
            relatorio.append("")
            for necessidade in necessidades:
                relatorio.append(f"{necessidade}")
                relatorio.append("")
    
    # An√°lise do Instagram
    if instagram_url and analysis_data.get('instagram_analysis'):
        instagram_rel = analysis_data['instagram_analysis'].get('relatorio', {})
        
        relatorio.append(f"An√°lise do Instagram: {instagram_url}")
        relatorio.append("")
        
        # Status do perfil
        perfil_analise = instagram_rel.get('perfil_analise', '')
        if perfil_analise:
            relatorio.append(f"Status do Perfil: {perfil_analise}")
            relatorio.append("")
        
        # Atividade
        atividade = instagram_rel.get('atividade_status', '')
        if atividade and 'sem atividade' in atividade.lower():
            relatorio.append(atividade)
            relatorio.append("")
        
        # Tipo de conta e bio
        tipo_conta = instagram_rel.get('tipo_conta', '')
        bio_status = instagram_rel.get('bio_status', '')
        if tipo_conta or bio_status:
            relatorio.append(f"Configura√ß√£o: {tipo_conta}. {bio_status}")
            relatorio.append("")
        
        # Estrat√©gias
        estrategias = instagram_rel.get('estrategias_recomendadas', [])
        if estrategias:
            relatorio.append("Estrat√©gias Recomendadas para Instagram:")
            relatorio.append("")
            for estrategia in estrategias:
                relatorio.append(f"{estrategia}")
                relatorio.append("")
    
    # Conclus√£o personalizada
    relatorio.append("Com nosso meet, entregaremos um diagn√≥stico mais completo e uma proposta personalizada para alcan√ßar novos resultados.")
    
    return "\n".join(relatorio)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'ok', 'message': 'Servidor funcionando'})

# Rotas para servir arquivos est√°ticos do frontend
@app.route('/')
def index():
    frontend_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'frontend')
    return send_from_directory(frontend_path, 'index.html')

@app.route('/<path:filename>')
def static_files(filename):
    frontend_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'frontend')
    return send_from_directory(frontend_path, filename)

if __name__ == '__main__':
    print("üöÄ Iniciando servidor Flask...")
    print(f"üìç Servidor rodar√° em: http://0.0.0.0:5000")
    print(f"üìÅ Frontend ser√° servido de: {os.path.join(os.path.dirname(os.path.dirname(__file__)), 'frontend')}")
    app.run(host='0.0.0.0', port=5000, debug=True)